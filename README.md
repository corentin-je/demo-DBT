# ðŸ›ï¸ Ecommerce DBT Project

**Objectif :** Projet DBT complet pour une plateforme ecommerce, avec donnÃ©es brutes intentionnellement "sales" pour pratiquer le nettoyage et la qualitÃ©.

**Timeline :** 2 jours (Mardi + Mercredi)  
**Format :** Staging â†’ Intermediate â†’ Marts + Tests + Data Contracts + Airflow

---

## ðŸ“ Structure du projet

```
ecommerce_dbt_project/
â”œâ”€â”€ dbt_project.yml          # Config DBT
â”œâ”€â”€ profiles.yml             # Connexion DB (Ã  configurer)
â”œâ”€â”€ README.md                # Ce fichier
â”œâ”€â”€ DATA_SETUP.md            # Instructions setup donnÃ©es
â”œâ”€â”€ data/                    # CSV bruts
â”‚   â”œâ”€â”€ raw_customers.csv
â”‚   â”œâ”€â”€ raw_products.csv
â”‚   â”œâ”€â”€ raw_orders.csv
â”‚   â”œâ”€â”€ raw_order_items.csv
â”‚   â””â”€â”€ raw_payments.csv
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ _documentation.yml   # Global documentation
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ schema.yml
â”‚   â”‚   â”œâ”€â”€ stg_customers.sql
â”‚   â”‚   â”œâ”€â”€ stg_products.sql
â”‚   â”‚   â”œâ”€â”€ stg_orders.sql
â”‚   â”‚   â”œâ”€â”€ stg_order_items.sql
â”‚   â”‚   â””â”€â”€ stg_payments.sql
â”‚   â”œâ”€â”€ intermediate/
â”‚   â”‚   â”œâ”€â”€ schema.yml
â”‚   â”‚   â”œâ”€â”€ int_orders_enriched.sql
â”‚   â”‚   â””â”€â”€ int_customer_lifetime.sql
â”‚   â””â”€â”€ marts/
â”‚       â”œâ”€â”€ schema.yml
â”‚       â”œâ”€â”€ fct_orders.sql
â”‚       â”œâ”€â”€ dim_customers.sql
â”‚       â””â”€â”€ audit_data_quality.sql
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ custom_tests/
â”‚   â”‚   â”œâ”€â”€ assert_positive_revenue.sql
â”‚   â”‚   â””â”€â”€ assert_valid_payment_methods.sql
â”‚   â””â”€â”€ generic_tests/  (via schema.yml)
â”œâ”€â”€ macros/
â”‚   â”œâ”€â”€ days_since.sql
â”‚   â””â”€â”€ generate_business_day_diff.sql
â”œâ”€â”€ snapshots/
â”‚   â””â”€â”€ snap_dim_customers.sql
â””â”€â”€ dags/
    â””â”€â”€ ecommerce_pipeline.py  # Airflow DAG
```

---

## ðŸš€ Quick Start

### 1ï¸âƒ£ Setup PostgreSQL + DonnÃ©es

Voir `DATA_SETUP.md` pour les instructions dÃ©taillÃ©es.

```bash
# Create DB & tables
psql postgres -f DATA_SETUP.md

# Load CSVs
\COPY raw.raw_customers FROM 'data/raw_customers.csv' WITH (FORMAT csv, HEADER true);
# ... (rÃ©pÃ©ter pour tous les fichiers)
```

### 2ï¸âƒ£ Configure DBT

```bash
# Update profiles.yml
vim ~/.dbt/profiles.yml

# Ajouter :
ecommerce_dbt:
  target: dev
  outputs:
    dev:
      type: postgres
      host: localhost
      user: dbt_user
      password: [your_password]
      port: 5432
      dbname: ecommerce_prod
      schema: ecommerce_dev
      threads: 4
      keepalives_idle: 0
```

### 3ï¸âƒ£ Initialize DBT Project

```bash
cd ecommerce_dbt_project
dbt deps         # Install packages
dbt debug        # Test connection
dbt parse        # Parse models
```

### 4ï¸âƒ£ Run Models

```bash
dbt run          # Run all models
dbt test         # Run tests
dbt docs generate
dbt docs serve   # View documentation
```

---

## ðŸ“Š Data Flow

```
Raw Data (5 tables)
    â†“
Staging (5 models - CLEAN)
    â†“ Tests (unique, not_null, relationships)
Intermediate (2 models - ENRICH)
    â†“ Tests
Marts (2 models - AGGREGATE)
    â†“ Data Contracts + Tests
Analytics (Dashboards / APIs)
```

---

## ðŸŽ¯ Couches DBT

### **Couche 1 : Staging (Nettoyage)**

Chaque modÃ¨le raw a son stg Ã©quivalent :

| Raw | Staging | Nettoyage |
|-----|---------|-----------|
| `raw_customers` | `stg_customers` | DÃ©dup, normalise email, dates |
| `raw_products` | `stg_products` | Type conversions (price) |
| `raw_orders` | `stg_orders` | Normalise statuts, dates |
| `raw_order_items` | `stg_order_items` | Valide intÃ©gritÃ© |
| `raw_payments` | `stg_payments` | Normalise methods, statuts |

**Tests staging :**
- `unique` : pas de doublons clÃ©s
- `not_null` : colonnes obligatoires
- `relationships` : clÃ©s externes valides
- `accepted_values` : domaines fermÃ©s

---

### **Couche 2 : Intermediate (Enrichissement)**

| ModÃ¨le | EntrÃ©es | Sortie |
|--------|---------|--------|
| `int_orders_enriched` | stg_orders + stg_customers + stg_order_items | Orders avec client & produits |
| `int_customer_lifetime` | int_orders_enriched | CLV, AOV, order_count par customer |

**Objectif :** PrÃ©parer les donnÃ©es pour les marts (dimensions/faits)

---

### **Couche 3 : Marts (Analytics)**

#### Fact Table : `fct_orders`
```sql
-- Columns:
- order_key (surrogate, generated via dbt_utils)
- order_id
- customer_id
- order_date
- order_total
- payment_total
- payment_count
- order_category
- is_payment_complete

-- Tests:
- order_id UNIQUE + NOT NULL
- customer_id references dim_customers
- order_total > 0
```

#### Dimension Table : `dim_customers`
```sql
-- Columns:
- customer_id
- first_name, last_name, email
- signup_date
- total_orders
- completed_orders
- cancelled_orders
- customer_lifetime_value (CLV)
- avg_order_value
- customer_segment (VIP/Loyal/Regular)
- is_active_customer (last 90 days)
- days_since_last_order

-- Tests:
- customer_id UNIQUE + NOT NULL
- total_orders > 0
- customer_lifetime_value > 0

-- Data Contract:
- SchÃ©ma garanti (colonnes, types, nullability)
```

#### Audit Model : `audit_data_quality`
```sql
-- Monitor:
- Row counts (raw vs staging vs marts)
- Volume anomalies (alert if > Â±20%)
- Data freshness (last updated timestamp)
```

---

## âœ… Tests & Quality

### Generic Tests (via schema.yml)

```yaml
tests:
  - unique: [order_id]
  - not_null: [customer_id]
  - relationships:
      column: customer_id
      to: ref('dim_customers')
      field: customer_id
  - accepted_values:
      values: ['completed', 'pending', 'cancelled']
```

### Custom Tests

```sql
-- tests/assert_positive_revenue.sql
SELECT customer_id, SUM(order_total) as total
FROM {{ ref('fct_orders') }}
GROUP BY customer_id
HAVING SUM(order_total) < 0
```

### Data Contracts

```yaml
# models/marts/schema.yml
- name: fct_orders
  config:
    contract:
      enforced: true
  columns:
    - name: order_id
      data_type: integer
      constraints:
        - type: not_null
        - type: unique
```

---

## ðŸ“ˆ Macros

### `days_since(date_column)`
Calcule le nombre de jours depuis une date donnÃ©e :
```sql
SELECT 
    customer_id,
    {{ days_since('last_order_date') }} as days_since_last_order
FROM int_customer_lifetime
```

### `generate_business_day_diff(start_date, end_date)`
Calcule business days (excluant weekends) :
```sql
SELECT 
    order_id,
    {{ generate_business_day_diff('order_date', 'delivery_date') }} as fulfillment_days
FROM fct_orders
```

---

## ðŸ“¸ Snapshots (SCD Type 2)

Track customer dimension changes over time :

```sql
-- snapshots/snap_dim_customers.sql
SELECT 
    customer_id,
    customer_segment,
    customer_lifetime_value,
    is_active_customer
FROM {{ ref('dim_customers') }}
```

**Colonnes auto :**
- `dbt_valid_from` : quand changement detectÃ©
- `dbt_valid_to` : quand nouveau changement
- `dbt_scd_id` : hash unique
- `dbt_updated_at` : timestamp du changement

---

## ðŸ”„ Airflow Orchestration

DAG simple qui orchestre le pipeline DBT :

```python
# dags/ecommerce_pipeline.py
from airflow import DAG
from airflow.operators.bash import BashOperator

with DAG(
    'ecommerce_dbt_pipeline',
    schedule_interval='0 2 * * *',  # Daily 2am
    ...
) as dag:
    dbt_run >> dbt_test >> dbt_docs
```

**TÃ¢ches :**
1. `dbt_run` : ExÃ©cuter les modÃ¨les
2. `dbt_test` : Lancer les tests
3. `dbt_docs` : GÃ©nÃ©rer documentation

**Alertes :**
- Slack notification si failures
- Retry automatique (1x)

---

## ðŸ“š Documentation

### Auto-Generated (dbt docs)

```bash
dbt docs generate
dbt docs serve
# Browse http://localhost:8080
```

**Contient :**
- Lineage graph (raw â†’ staging â†’ intermediate â†’ marts)
- Description de chaque modÃ¨le
- Descriptions de colonnes
- SQL queries
- Tests appliquÃ©s

### Business Glossary

```yaml
# models/_business_glossary.yml
terms:
  - name: CLV
    description: Customer Lifetime Value = Total revenue par customer
    synonyms: [total_spent, lifetime_value]
```

---

## ðŸŽ¯ Checklist Completion

### Day 1 (Mardi)
- [ ] Setup PostgreSQL + donnÃ©es CSV chargÃ©es
- [ ] 5 modÃ¨les staging complets + tests
- [ ] 2 modÃ¨les intermediate complets
- [ ] 2 modÃ¨les marts (fct + dim) complets
- [ ] 30+ tests DBT passant
- [ ] Data contracts sur marts
- [ ] Audit model operational
- [ ] Documentation dbt docs gÃ©nÃ©rÃ©e

### Day 2 (Mercredi)
- [ ] Airflow DAG simple operationnel
- [ ] Tests + Great Expectations (optionnel)
- [ ] Portfolio GitHub : push complet
- [ ] Mock interview (3-4h)
- [ ] Repos finals : Jaffle Shop + ecommerce
- [ ] Sommeil 8h minimum ðŸ˜´

---

## ðŸš€ Usage en Interview

**Comment rÃ©fÃ©rencer ce projet :**

> "J'ai construit hier un pipeline ecommerce complet :
> - 5 sources raw avec 30+ data quality issues
> - 3 couches DBT (staging/intermediate/marts)
> - 30+ tests + data contracts
> - 2 tables analytics-ready (facts + dimensions)
> - OrchestrÃ© avec Airflow (daily trigger)
> - Portfolio sur GitHub"

---

## ðŸ“ž Troubleshooting

### Erreur : "relation does not exist"
```
â†’ VÃ©rifiez permissions dbt_user sur schema raw
GRANT SELECT ON ALL TABLES IN SCHEMA raw TO dbt_user;
```

### Erreur : "type mismatch"
```
â†’ VÃ©rifiez data contracts vs donnÃ©es rÃ©elles
dbt parse --select fct_orders
```

### Erreur : "Airflow DAG not found"
```
â†’ VÃ©rifiez $AIRFLOW_HOME/dags/ecommerce_pipeline.py existe
```

---

## ðŸŽ“ Learning Outcomes

AprÃ¨s ce projet, vous maÃ®triserez :

âœ… Architecture DBT complÃ¨te (3 couches)  
âœ… Data quality (tests, contracts, audit)  
âœ… Nettoyage donnÃ©es rÃ©alistes  
âœ… Macros + code rÃ©utilisable  
âœ… Governance (metadata, lineage, documentation)  
âœ… Orchestration (Airflow basics)  
âœ… Portfolio-ready code  

---

**Bonne chance ! ðŸš€**

Pour questions : voir DATA_SETUP.md et dbt docs



